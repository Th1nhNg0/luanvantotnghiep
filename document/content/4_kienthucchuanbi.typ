= Kiến thức chuẩn bị <phan1>


== Hệ thống văn bản quy phạm pháp luật

Hệ thống những văn bản quy phạm pháp luật là hình thức biểu hiện mối liên hệ bên ngoài của pháp luật thông qua các loại văn bản quy phạm pháp luật có giá trị cao thấp khác nhau được các cơ quan Nhà nước có thẩm quyền ban hành theo một trình tự, thủ tục do pháp luật quy định, nhưng đều tồn tại trong thể thống nhất.

Các văn bản quy phạm pháp luật tạo nên hệ thống pháp luật các văn bản quy phạm pháp luật có những đặc điểm:

- Nội dung của các văn bản quy phạm pháp luật là các quy phạm pháp luật do các cơ quan Nhà nước có thẩm quyền ban hành.

- Các văn bản quy phạm pháp luật đều có tên gọi khác nhau (luật, nghị định, pháp lệnh…) do Hiến pháp quy định. Giá trị pháp lý của chúng cao thấp khác nhau do vị trí của cơ quan Nhà nước trong bộ máy nhà nước có quy định.

- Các văn bản quy phạm pháp luật có hiệu lực trong không gian (hiệu lực trong phạm vi khu vực lãnh thổ) và hiệu lực theo thời gian (bắt đầu có hiệu lực hay hết hiệu lực), hiệu lực theo nhóm người (có hiệu lực đối với nhóm người này và không có hiệu lực đối với nhóm người khác).

Theo Hiến pháp năm 2013, Luật Ban hành văn bản quy phạm pháp luật năm 2015 quy định hệ thống những văn bản quy phạm pháp luật gồm các văn bản có giá trị pháp lý như sau:

1. Hiến pháp.
2. Bộ luật, luật, nghị quyết của Quốc hội.
3. Pháp lệnh, nghị quyết của Ủy ban thường vụ Quốc hội; nghị quyết liên tịch giữa Ủy ban thường vụ Quốc hội với Đoàn Chủ tịch Ủy ban trung ương Mặt trận Tổ quốc Việt Nam; nghị quyết liên tịch giữa Ủy ban thường vụ Quốc hội, Chính phủ, Đoàn Chủ tịch Ủy ban trung ương Mặt trận Tổ quốc Việt Nam.
4. Lệnh, quyết định của Chủ tịch nước.
5. Nghị định của Chính phủ; nghị quyết liên tịch giữa Chính phủ với Đoàn Chủ tịch Ủy ban trung ương Mặt trận Tổ quốc Việt Nam.
6. Quyết định của Thủ tướng Chính phủ.
7. Nghị quyết của Hội đồng Thẩm phán Tòa án nhân dân tối cao.
8. Thông tư của Chánh án Tòa án nhân dân tối cao; thông tư của Viện trưởng Viện kiểm sát nhân dân tối cao; thông tư của Bộ trưởng, Thủ trưởng cơ quan ngang bộ; quyết định của Tổng Kiểm toán nhà nước.
9. Thông tư liên tịch giữa Chánh án Tòa án nhân dân tối cao, Viện trưởng Viện kiểm sát nhân dân tối cao, Tổng Kiểm toán nhà nước, Bộ trưởng, Thủ trưởng cơ quan ngang bộ. Không ban hành thông tư liên tịch giữa Bộ trưởng, Thủ trưởng cơ quan ngang bộ.
10. Nghị quyết của Hội đồng nhân dân tỉnh, thành phố trực thuộc Trung ương (sau đây gọi chung là cấp tỉnh).
11. Quyết định của Ủy ban nhân dân cấp tỉnh.
12. Văn bản quy phạm pháp luật của chính quyền địa phương ở đơn vị hành chính - kinh tế đặc biệt.
13. Nghị quyết của Hội đồng nhân dân huyện, quận, thị xã, thành phố thuộc tỉnh, thành phố thuộc thành phố trực thuộc Trung ương (sau đây gọi chung là cấp huyện).
14. Quyết định của Ủy ban nhân dân cấp huyện.
15. Nghị quyết của Hội đồng nhân dân xã, phường, thị trấn (sau đây gọi chung là cấp xã).
16. Quyết định của Ủy ban nhân dân cấp xã.


== Large Language Model

Large Language Model (LLM) là một mô hình ngôn ngữ sử dụng deep neural network #footnote([Deep neural network (DNN) là một mạng nơ-ron nhân tạo (ANN) với nhiều lớp ẩn giữa lớp đầu vào và lớp đầu ra. DNN có thể được huấn luyện với dữ liệu không được gán nhãn và được sử dụng để phân loại, phân cụm và trích xuất đặc trưng. DNN là một phần của họ các mô hình học sâu (deep learning).]) với số lượng tham số rất lớn (thường là hàng tỷ trọng số hoặc nhiều hơn), được huấn luyện trên lượng lớn văn bản không được gán nhãn bằng cách sử dụng học tự giám sát hoặc học bán giám sát (supervised learning và unsupervised learning). LLM xuất hiện vào khoảng năm 2018 và thể hiện khả năng xử lý tốt nhiều loại nhiệm vụ khác nhau. Điều này đã thay đổi tâm điểm của nghiên cứu xử lý ngôn ngữ tự nhiên từ mô hình giám sát chuyên biệt cho từng nhiệm vụ sang mô hình đa năng có thể thích ứng với nhiều tình huống. LLM thường được áp dụng trong các ứng dụng xử lý ngôn ngữ tự nhiên (NLP) như hiểu, tóm tắt, dịch, sinh và dự đoán văn bản mới.

Một ví dụ của LLM là GPT, viết tắt của Generative Pre-trained Transformer. GPT là một mô hình biến đổi được tiền huấn luyện trên một tập dữ liệu văn bản rộng lớn, sau đó được tinh chỉnh cho các nhiệm vụ cụ thể như sinh văn bản, trả lời câu hỏi, phân loại văn bản và hơn thế nữa. GPT có khả năng sinh ra các đoạn văn bản có ý nghĩa và trôi chảy từ một đầu vào bất kỳ, chẳng hạn như một câu, một từ khóa hoặc một hình ảnh. Phiên bản mới nhất của GPT là GPT-4@openai2023gpt4, có khoảng 100 tỷ tham số và được huấn luyện trên khoảng 10 triệu từ.

==  Generative Pre­trained Transformer

Generative Pre-trained Transformer (GPT), một loại mô hình học sâu có khả năng sinh văn bản tự động dựa trên dữ liệu huấn luyện lớn. GPT được phát triển bởi OpenAI #footnote([OpenAI là một tổ chức nghiên cứu trí tuệ nhân tạo phi lợi nhuận được thành lập vào tháng 12 năm 2015, có trụ sở tại San Francisco, California. OpenAI được thành lập bởi Elon Musk, Sam Altman và các nhà nghiên cứu khác, với mục tiêu "điều tra và thúc đẩy một trí tuệ nhân tạo thân thiện với con người]). GPT có nhiều phiên bản khác nhau, từ GPT-1 ra mắt vào năm 2018 đến GPT-3 ra mắt vào năm 2020. Mỗi phiên bản đều có số lượng tham số và khả năng sinh văn bản cao hơn phiên bản trước. Ví dụ, GPT-3 có 175 tỷ tham số và có thể sinh văn bản với độ dài tối đa là 2048 từ. GPT có thể áp dụng cho nhiều ứng dụng khác nhau, như viết tiêu đề, tóm tắt, bài luận, thơ, hội thoại và nhiều thứ khác. Ví dụ, GPT-3 có thể viết một bài luận ngắn về tác dụng của việc đọc sách hoặc một câu chuyện ngắn về một chú mèo tên Tom. GPT là một trong những mô hình học sâu tiên tiến nhất hiện nay trong lĩnh vực xử lý ngôn ngữ tự nhiên.

== Embeddings

Embedding là một kỹ thuật biểu diễn các nội dung số như hình, chữ, âm thanh thành một danh sách các con số (vector). Quá trình này giúp cho các mô hình machine learning có thể "hiểu" được nội dung đó.

Embeddings thường được sử dụng trong các ứng dụng như:
- Search (kết quả được sắp xếp theo mức độ liên quan đến một chuỗi truy vấn)
- Clustering (các chuỗi văn bản được nhóm lại theo độ tương tự)
- Recommendations (các mục có chuỗi văn bản liên quan được đề xuất)
- Anomaly detection (các điểm ngoại lệ có độ tương tự thấp được xác định)
- Diversity measurement (phân tích phân phối độ tương tự)
- Classification (các chuỗi văn bản được phân loại theo nhãn tương tự nhất)



== TF-IDF

TF-IDF (Term Frequency – Inverse Document Frequency) là 1 kĩ thuật sử dụng trong khai phá dữ liệu văn bản. Trọng số này được sử dụng để đánh giá tầm quan trọng của một từ trong một văn bản. Giá trị cao thể hiện độ quan trọng cao và nó phụ thuộc vào số lần từ xuất hiện trong văn bản nhưng bù lại bởi tần suất của từ đó trong tập dữ liệu. Một vài biến thể của tf-idf thường được sử dụng trong các hệ thống tìm kiếm như một công cụ chính để đánh giá và sắp xếp văn bản dựa vào truy vấn của người dùng.  Tf-idf cũng được sử dụng để lọc những từ stopwords trong các bài toán như tóm tắt văn bản và phân loại văn bản.

*TF: Term Frequency(Tần suất xuất hiện của từ)* là số lần từ xuất hiện trong văn bản. Vì các văn bản có thể có độ dài ngắn khác nhau nên một số từ có thể xuất hiện nhiều lần trong một văn bản dài hơn là một văn bản ngắn. Như vậy, term frequency thường được chia cho độ dài văn bản (tổng số từ trong một văn bản).

$ "TF"(t,d)=(f(t,d))/(max{f(w,d):w in d}) $

Trong đó:
- $"TF"(t, d)$: tần suất xuất hiện của từ $t$ trong văn bản $d$
- $f(t, d)$: Số lần xuất hiện của từ $t$ trong văn bản $d$
- $max({f(w, d) : w in d})$: Số lần xuất hiện của từ có số lần xuất hiện nhiều nhất trong văn bản

*IDF: Inverse Document Frequency(Nghịch đảo tần suất của văn bản)*, giúp đánh giá tầm quan trọng của một từ. Khi tính toán TF, tất cả các từ được coi như có độ quan trọng bằng nhau. Nhưng một số từ như "is","of" và "that" thường xuất hiện rất nhiều lần nhưng độ quan trọng là không cao. Như thế ta cần giảm độ quan trọng của những từ này xuống.

$ "IDF"(t,D) = log abs(D)/abs({d in D:t in d}) $

Trong đó:
- $"IDF"(t, D)$: giá trị idf của từ t trong tập văn bản
- $abs(D)$: Tổng số văn bản trong tập $D$
- $abs({d in D : t in d})$: thể hiện số văn bản trong tập $D$ có chứa từ $t$.

Việc sử dụng logarit nhằm giúp giá trị tf-idf của một từ nhỏ hơn, do công thức tính tf-idf của một từ trong 1 văn bản là tích của tf và idf của từ đó.

Cụ thể, công thức tính tf-idf hoàn chỉnh như sau: 
$ "TDIDF"(t, d, D) = "TF"(t, d) * "IDF"(t, D) $
Khi đó những từ có giá trị TF-IDF cao là những từ xuất hiện nhiều trong văn bản này, và xuất hiện ít trong các văn bản khác. Việc này giúp lọc ra những từ phổ biến và giữ lại những từ có giá trị cao (từ khoá của văn bản đó).

== BM25

Phương pháp có tên BM25 (BM – best match), thường gọi "Okapi BM25", vì lần đầu tiên công thức được sử dụng trong hệ thống tìm kiếm Okapi, được sáng lập tại trường đại học London những năm 1980 và 1990.

Công thức tính điểm của BM25 được định nghĩa như sau:

$ "BM25"(D, Q) = sum_(i=1)^n "IDF"(q_i,D) (f(q_i,D)*(k_1+1))/(f(q_i)+k_1*(1-b+b*abs(D)/d_"avg")) $

Trong đó:
- $f(q_i,D)$: là số lần mà term $q_i$ xuất hiện trong tất cả các tài liệu $D$
- $abs(D)$ là số từ trong tất cả các tài liệu  $D$
- $d_"avg"$ là số lượng từ trung bình trong mỗi tài liệu
- $b$ và $k_1$ là các tham số của BM25

So với thuật toán TF-IDF, BM25 có ưu điểm là có thể xử lý được các văn bản dài. Điều này là do công thức của BM25 có thêm một số tham số như $b$ và $k_1$ để điều chỉnh. Các tham số này giúp cho BM25 có thể xử lý được các văn bản dài hơn.

== Sentence Transformers

Sentence Transformers@reimers-2019-sentence-bert là một python framework cho tác vụ embeddings. Nó được xem là state-of-the-art#footnote(["state-of-the-art" những gì hiện đại và tiên tiến nhất]) trong tác vụ embeddings.

Semantic Search là một ứng dụng của Sentence Transformers. Nó cho phép tìm kiếm các văn bản có nội dung tương tự với một văn bản đầu vào. Để thực hiện ứng dụng này, ta cần có một bộ dữ liệu các văn bản và một mô hình embeddings. Mô hình embeddings này sẽ nhúng các văn bản trong bộ dữ liệu thành các vector. Sau đó, ta sẽ tính khoảng cách giữa vector của văn bản đầu vào với các vector của các văn bản trong bộ dữ liệu.

Khoảng cách giữa hai vector đo lường mức độ liên quan của chúng. Khoảng cách nhỏ cho thấy mức độ liên quan cao và khoảng cách lớn cho thấy mức độ liên quan thấp.

#figure(
    image("../images/SemanticSearch.png",width: 50%),
    caption: [
        Semantic Search
    ]
)


== Chroma

Chroma là một cơ sở dữ liệu nhúng mã nguồn mở được thiết kế để lưu trữ các vector nhúng (embeddings) và cho phép tìm kiếm các vector gần nhất thay vì tìm kiếm theo chuỗi con như một cơ sở dữ liệu truyền thống. 

Chroma cung cấp các công cụ để:
- Lưu trữ embeddings và metadata (dữ liệu mô tả) của chúng
- Nhúng tài liệu và truy vấn
- Tìm kiếm embeddings

#figure(
    image("../images/chroma.svg"),
    caption: [
        Cơ sở dữ liệu Chroma
    ]
)

== Langchain

Langchain là một framework được sinh ra để tận dụng sức mạnh của các mô hình ngôn ngữ lớn LLM như ChatPGT, LLaMA… để tạo ra các ứng dụng trong thực tế. Nó giúp cho việc tương tác với các mô hình ngôn ngữ lớn trở nên dễ dàng hơn và cho phép các ứng dụng tận dụng thêm các thông tin từ nhiều nguồn data khác của bên thứ 3 như Google, Notion, Facebook… cũng như cung cấp các component cho phép sử dụng các language model trong nhiều tình huống khác nhau trên thực tế.

#figure(
    image("../images/flowise.png"),
    caption: [
        Flowise, visual tool để xây dựng các ứng dụng LLM, được xây dựng trên nền tảng Langchain
    ]
)

== ChatGPT

ChatGPT là một chatbot AI hoạt động dựa trên mô hình GPT-3.5 được phát triển bởi OpenAI. ChatGPT có khả năng tương tác với người dùng thông qua việc trả lời các câu hỏi và hoàn thành các tác vụ liên quan đến ngôn ngữ như viết kịch bản, lời thoại, dịch thuật, tìm kiếm thông tin,... mà không giới hạn về chủ đề. ChatGPT được đào tạo bằng phương pháp Học tăng cường từ phản hồi của con người (RLHF – Reinforcement Learning from Human Feedback)@lambert2022illustrating, nên có thể hiểu ngữ cảnh, ghi nhớ thông tin người dùng nói, dự đoán nhu cầu của họ để đưa ra các phản hồi chính xác nhất. ChatGPT là một ứng dụng nổi bật của GPT-3, một trong những mô hình xử lý ngôn ngữ tự nhiên (Natural Language Processing) tiên tiến nhất hiện nay. ChatGPT có thể được áp dụng cho nhiều lĩnh vực khác nhau như chăm sóc khách hàng, sáng tạo nội dung, giáo dục,... ChatGPT là một bước tiến quan trọng trong lĩnh vực trí tuệ nhân tạo và có tiềm năng thay đổi cách con người giao tiếp và học tập trong tương lai.

#figure(
    image("../images/ChatGPT_Diagram.svg"),
    caption: [
        Sơ đồ hoạt động của ChatGPT
    ]
)

== Bing AI


Bing AI@bingai là một chatbot trí tuệ nhân tạo (AI) được phát triển bởi Microsoft và ra mắt vào năm 2023. Nó được xây dựng trên nền tảng của mô hình ngôn ngữ lớn (LLM) GPT-4 của OpenAI và đã được tinh chỉnh sử dụng cả các kỹ thuật học có giám sát và học tăng cường.

Bing AI không chỉ sinh văn bản dựa theo xác suất như ChatGPT của OpenAI, mà còn có thể dẫn được nguồn của văn bản mà nó tham chiếu tới do đó nội dung có tính xác thực cao hơn. Ngoài ra, Bing AI còn có thể trả lời các câu hỏi phức tạp, tương tác với người dùng qua chat, và tạo ra nội dung sáng tạo như thơ, truyện, mã nguồn, bài viết, bài hát và nhiều thứ khác.

#figure(
    image("../images/bing.png"),
    caption: [
       Giao diện của Bing AI
    ]
)


== Open-Domain Question Answering

Open-domain Question Answering (ODQA) là một loại nhiệm vụ ngôn ngữ, yêu cầu mô hình tạo ra câu trả lời cho các câu hỏi bằng ngôn ngữ tự nhiên. Câu trả lời đúng là khách quan, vì vậy ta có thể dễ dàng đánh giá hiệu suất của mô hình.

Ví dụ:

```
Question: What did Albert Einstein win the Nobel Prize for?
Answer: The law of the photoelectric effect.
```


Phần "open-domain" đề cập đến việc thiếu bối cảnh liên quan đến bất kỳ câu hỏi thực tế nào được hỏi một cách tùy ý. Trong trường hợp trên, mô hình chỉ lấy câu hỏi làm đầu vào nhưng không cung cấp bất kỳ dẫn chứng nào về "What did Albert Einstein win the Nobel Prize for", trong đó thuật ngữ "The law of the photoelectric effect" có thể được đề cập. Trong trường hợp cả câu hỏi và bối cảnh được cung cấp, nhiệm vụ được gọi là *Reading comprehension (RC)*.

Một mô hình ODQA có thể hoạt động với hoặc không có quyền truy cập vào nguồn tri thức bên ngoài (ví dụ: Wikipedia) và hai điều kiện này được gọi là open-book hoặc closed-book, trả lời câu hỏi mở hoặc đóng.

Khi xét về các loại câu hỏi open-domain khác nhau, phân loại của Lewis, et al., 2020@lewis2020question được xem là khá phù hợp, phân loại theo thứ tự tăng dần độ khó:

1. Một mô hình có thể trả lời đúng với câu trả lời cho một câu hỏi đã được thấy trong quá trình huấn luyện.
2. Một mô hình có thể trả lời đúng với câu trả lời cho một câu hỏi mới ở thời gian kiểm tra và chọn một câu trả lời từ tập các câu trả lời mà nó đã thấy trong quá trình huấn luyện.
3. Một mô hình có thể trả lời đúng với các câu hỏi mới có câu trả lời không có trong tập dữ liệu huấn luyện.

#figure(
    image("../images/QA-summary.png"),
    caption: [Sơ lược về 3 mô hình ODQA]
)

Như đã đề cập từ trước, ChatGPT là Generator, Bing AI là retriever-Generator. 

== Multimodal model

Multimodal Model là một hệ thống trí tuệ nhân tạo xử lý nhiều dạng dữ liệu cảm quan cùng lúc. Học trong Multimodal Model kết hợp các dữ liệu từ các cảm biến và nguồn khác vào một mô hình, tạo ra các dự đoán linh hoạt hơn.

Multimodal Model gồm nhiều mạng nơ-ron unimodal, xử lý từng dạng dữ liệu riêng biệt. Sau đó, các đặc trưng được mã hóa từ các mạng unimodal được kết hợp lại để tạo ra một đại diện chung cho tất cả các dạng dữ liệu. Cuối cùng, đại diện chung này được sử dụng để thực hiện các nhiệm vụ mong muốn.

Multimodal Model là đề tài nóng của trí tuệ nhân tạo. Ví dụ nổi bật là GPT-4 của OpenAI, một mô hình lớn xử lý văn bản và hình ảnh và tạo ra văn bản. GPT-4 đã đạt được hiệu suất ở mức con người trên nhiều tiêu chuẩn chuyên nghiệp và học thuật. Multimodal Model có tiềm năng ứng dụng trong nhiều lĩnh vực khác nhau.

#[
    #set text(size:11pt)
    #figure(
        [
        #grid(
            columns: (60pt, 1fr),
            gutter: 10pt,
            align(left)[User],
            align(left)[Answer question I.1.a. Think step-by-step.
            #image("../images/Multimodal.png")
            ],
            align(left)[GPT-4],
            align(left)[
                To answer question I.1.a, we need to express the $T(x)$ in every point of the conductive bar, which is characterized by the abscissa $x$. We are given that $T(0) = T_0$ and $T(L) = T_b$.

                For a stationary regime, the heat equation for the one-dimensional heat conduction in the bar is:\
                $d^2 T \/ d x^2 = 0$

                Integrating once, we get:\
                $d T \/d x = C_1$
                
                Integrating a second time:\
                $T(x) = C_1 x + C_2$
                
                To determine the constants $C_1$ and $C_2$, we use the boundary conditions:\
                $T(0) = T_0$, which gives $C_2 = T_0$\
                $T(L) = T_b$, which gives $C_1 = (T_b − T_0)\/L$

                Finally, the expression for $T(x)$ is:\
                $T(x) = (T_b − T_0) ∗ (x\/L) + T_0$
                
                This represents a linear temperature profile along the conductive bar, with a slope of $(T_b − T_0)\/L$.
            ]),
        ],
        caption: [
            Ví dụ về Multimodal Model, người dùng yêu cầu GPT­4 trả lời câu hỏi về bài tập vật lý được viết bằng tiếng Pháp, bài tập là một hình ảnh.
        ]
    )
]


