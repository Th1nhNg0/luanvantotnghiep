{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "import bs4\n",
        "import requests\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from law_query_private import LawQuery,Tree\n",
        "from slugify import slugify\n",
        "import gzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # get luat hien hanh\n",
        "# req = requests.get('https://thuvienphapluat.vn/chinh-sach-phap-luat-moi/vn/thoi-su-phap-luat/tu-van-phap-luat/42248/danh-muc-luat-bo-luat-hien-hanh-tai-viet-nam')\n",
        "# soup = BeautifulSoup(req.text, 'html.parser')\n",
        "# luat_hien_hanh = soup.select('.newcontent a')\n",
        "# urls = []\n",
        "# for i in luat_hien_hanh:\n",
        "#     urls.append(i['href'])\n",
        "# urls = urls[1:]\n",
        "# # save to urls.txt\n",
        "# with open('urls.txt', 'w') as f:\n",
        "#     f.write('\\n'.join(urls))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "urls = []\n",
        "with open('urls2.txt', 'r') as f:\n",
        "    urls = f.read().split('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_text(url):\n",
        "    # get metadata\n",
        "    metadata_url='https://thuvienphapluat.vn/AjaxLoadData/LoadLuocDo.aspx?LawID={}&IstraiNghiem=True'\n",
        "    id = url.replace('.aspx','').split('-')[-1]\n",
        "    req=requests.get(metadata_url.format(id),headers={'referer': url})\n",
        "    if req.status_code != 200:\n",
        "        raise Exception('Error when get metadata')\n",
        "    soup = BeautifulSoup(req.text, 'html.parser')\n",
        "    metadata = soup.select_one('#viewingDocument')\n",
        "    metadata = {\n",
        "        'ten_van_ban': metadata.select_one('#viewingDocument > div:nth-child(1)').getText(strip=True), \n",
        "        'so_hieu_van_ban': metadata.select_one('#viewingDocument > div:nth-child(2) > div.ds.fl').getText(strip=True),\n",
        "        'loai_van_ban': metadata.select_one('#viewingDocument > div:nth-child(3) > div.ds.fl').getText(strip=True),\n",
        "        'linhvuc': metadata.select_one('#viewingDocument > div:nth-child(4) > div.ds.fl').getText(strip=True),\n",
        "        'noi_ban_hanh': metadata.select_one('#viewingDocument > div:nth-child(5) > div.ds.fl').getText(strip=True),\n",
        "        'nguoi_ky': metadata.select_one('#viewingDocument > div:nth-child(6) > div.ds.fl').getText(strip=True),\n",
        "        'ngay_ban_hanh': metadata.select_one('#viewingDocument > div:nth-child(7) > div.ds.fl').getText(strip=True),\n",
        "        'ngay_hieu_luc': metadata.select_one('#viewingDocument > div:nth-child(8) > div.ds.fl').getText(strip=True),\n",
        "        'ngay_cong_bao': metadata.select_one('#viewingDocument > div:nth-child(9) > div.ds.fl').getText(strip=True),\n",
        "        'so_cong_bao': metadata.select_one('#viewingDocument > div:nth-child(10) > div.ds.fl').getText(strip=True),\n",
        "        'tinh_trang': metadata.select_one('#viewingDocument > div:nth-child(11) > div.ds.fl').getText(strip=True),\n",
        "    }\n",
        "    req=requests.get(url)\n",
        "    soup = BeautifulSoup(req.text, 'html.parser')\n",
        "    html = soup.find('div', {'class':'content1'})\n",
        "    for element in html(text=lambda text: isinstance(text, bs4.Comment)):\n",
        "        element.extract()\n",
        "    for a in html.find_all('a', href=lambda x: x and x[0] == '#'):\n",
        "        a.extract()\n",
        "    for s in html.find_all(['script','style']):\n",
        "        s.extract()\n",
        "    ps = html.find_all(['p','h1','h2','h3','h4','h5','h6'])\n",
        "    content = ''\n",
        "    for p in ps:\n",
        "        text = p.text\n",
        "        lines = (line.strip() for line in text.splitlines())\n",
        "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
        "        text = ' '.join(chunk for chunk in chunks if chunk)\n",
        "        content += text + '\\n'\n",
        "    # delete - more than 3\n",
        "    content = re.sub(r'-{3,}', '', content)\n",
        "    content = re.sub(r'\\*{3,}', '', content)\n",
        "    # remove line with empty content\n",
        "    content = re.sub(r'^\\s+$', '', content, flags=re.MULTILINE)\n",
        "    # name = soup.find('h1').text.strip()\n",
        "    matches = re.finditer(r'^(chương [\\d\\w]+.*|phần thứ [\\d\\w]+.*)$', content, re.MULTILINE | re.IGNORECASE)\n",
        "    for i,match in enumerate(matches):\n",
        "        end = match.end()\n",
        "        while end < len(content) and content[end] != '\\n':\n",
        "            end += 1\n",
        "        if end < len(content) and content[end] == '\\n':\n",
        "            content = content[:end] + ':' + content[end+1:]\n",
        "    return metadata,content,html.prettify()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Luật Bảo hiểm xã hội 2014\n",
            "Văn bản hợp nhất 2089/VBHN-BHXH năm 2020 hợp nhất Quyết định về Quy trình thu bảo hiểm xã hội, bảo hiểm y tế, bảo hiểm thất nghiệp, bảo hiểm tai nạn lao động, bệnh nghề nghiệp; quản lý sổ bảo hiểm xã hội, thẻ bảo hiểm y tế do Bảo hiểm xã hội Việt Nam ban hành\n",
            "Thông tư 59/2015/TT-BLĐTBXH quy định chi tiết và hướng dẫn thi hành một số điều của Luật bảo hiểm xã hội về bảo hiểm xã hội bắt buộc do Bộ trưởng Bộ Lao động - Thương binh và Xã hội ban hành\n",
            "Nghị định 115/2015/NĐ-CP hướng dẫn Luật bảo hiểm xã hội về bảo hiểm xã hội bắt buộc\n",
            "Nghị định 146/2018/NĐ-CP hướng dẫn Luật bảo hiểm y tế\n",
            "Nghị định 28/2015/NĐ-CP hướng dẫn Luật Việc làm về bảo hiểm thất nghiệp\n",
            "Luật việc làm 2013\n",
            "Bộ luật Lao động 2019\n",
            "Thông tư 56/2017/TT-BYT về hướng dẫn Luật bảo hiểm xã hội và Luật an toàn vệ sinh lao động thuộc lĩnh vực y tế do Bộ trưởng Bộ Y tế ban hành\n",
            "Nghị định 134/2015/NĐ-CP hướng dẫn Luật Bảo hiểm xã hội về bảo hiểm xã hội tự nguyện\n",
            "Quyết định 28/2021/QĐ-TTg quy định về thực hiện chính sách hỗ trợ người lao động và người sử dụng lao động bị ảnh hưởng bởi đại dịch COVID-19 từ Quỹ bảo hiểm thất nghiệp do Thủ tướng Chính phủ ban hành\n",
            "Luật bảo hiểm y tế 2008\n",
            "Luật Bảo hiểm y tế sửa đổi 2014\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m url \u001b[39min\u001b[39;00m urls:\n\u001b[0;32m      3\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m----> 4\u001b[0m         metadata,text,html \u001b[39m=\u001b[39m get_text(url)\n\u001b[0;32m      5\u001b[0m         \u001b[39mprint\u001b[39m(metadata[\u001b[39m'\u001b[39m\u001b[39mten_van_ban\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m         name_slug \u001b[39m=\u001b[39m slugify(metadata[\u001b[39m'\u001b[39m\u001b[39mten_van_ban\u001b[39m\u001b[39m'\u001b[39m])[:\u001b[39m50\u001b[39m]\n",
            "Cell \u001b[1;32mIn[12], line 5\u001b[0m, in \u001b[0;36mget_text\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m      3\u001b[0m metadata_url\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://thuvienphapluat.vn/AjaxLoadData/LoadLuocDo.aspx?LawID=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m&IstraiNghiem=True\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[39mid\u001b[39m \u001b[39m=\u001b[39m url\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m.aspx\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m req\u001b[39m=\u001b[39mrequests\u001b[39m.\u001b[39;49mget(metadata_url\u001b[39m.\u001b[39;49mformat(\u001b[39mid\u001b[39;49m),headers\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mreferer\u001b[39;49m\u001b[39m'\u001b[39;49m: url})\n\u001b[0;32m      6\u001b[0m \u001b[39mif\u001b[39;00m req\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[0;32m      7\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError when get metadata\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m, url, params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
            "File \u001b[1;32mc:\\Users\\ngoph\\.conda\\envs\\research\\lib\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    787\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_request(\n\u001b[0;32m    791\u001b[0m     conn,\n\u001b[0;32m    792\u001b[0m     method,\n\u001b[0;32m    793\u001b[0m     url,\n\u001b[0;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout_obj,\n\u001b[0;32m    795\u001b[0m     body\u001b[39m=\u001b[39mbody,\n\u001b[0;32m    796\u001b[0m     headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39mchunked,\n\u001b[0;32m    798\u001b[0m     retries\u001b[39m=\u001b[39mretries,\n\u001b[0;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39mresponse_conn,\n\u001b[0;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39mpreload_content,\n\u001b[0;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39mdecode_content,\n\u001b[0;32m    802\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresponse_kw,\n\u001b[0;32m    803\u001b[0m )\n\u001b[0;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[0;32m    806\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\ngoph\\.conda\\envs\\research\\lib\\site-packages\\urllib3\\connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m     \u001b[39m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 467\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[0;32m    468\u001b[0m     \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    469\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mconn\u001b[39m.\u001b[39mtimeout)\n",
            "File \u001b[1;32mc:\\Users\\ngoph\\.conda\\envs\\research\\lib\\site-packages\\urllib3\\connectionpool.py:1092\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[39m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m conn\u001b[39m.\u001b[39mis_closed:\n\u001b[1;32m-> 1092\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m   1094\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n\u001b[0;32m   1095\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1096\u001b[0m         (\n\u001b[0;32m   1097\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnverified HTTPS request is being made to host \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mconn\u001b[39m.\u001b[39mhost\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1102\u001b[0m         InsecureRequestWarning,\n\u001b[0;32m   1103\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\ngoph\\.conda\\envs\\research\\lib\\site-packages\\urllib3\\connection.py:604\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    603\u001b[0m     sock: socket\u001b[39m.\u001b[39msocket \u001b[39m|\u001b[39m ssl\u001b[39m.\u001b[39mSSLSocket\n\u001b[1;32m--> 604\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m sock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[0;32m    605\u001b[0m     server_hostname: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n\u001b[0;32m    606\u001b[0m     tls_in_tls \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\ngoph\\.conda\\envs\\research\\lib\\site-packages\\urllib3\\connection.py:200\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \n\u001b[0;32m    197\u001b[0m \u001b[39m:return: New socket connection.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m     sock \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[0;32m    201\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport),\n\u001b[0;32m    202\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout,\n\u001b[0;32m    203\u001b[0m         source_address\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msource_address,\n\u001b[0;32m    204\u001b[0m         socket_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket_options,\n\u001b[0;32m    205\u001b[0m     )\n\u001b[0;32m    206\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39mgaierror \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    207\u001b[0m     \u001b[39mraise\u001b[39;00m NameResolutionError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m, e) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\ngoph\\.conda\\envs\\research\\lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[39mif\u001b[39;00m source_address:\n\u001b[0;32m     72\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[0;32m     74\u001b[0m \u001b[39m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[0;32m     75\u001b[0m err \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "items = []\n",
        "for url in urls:\n",
        "    try:\n",
        "        metadata,text,html = get_text(url)\n",
        "        print(metadata['ten_van_ban'])\n",
        "        name_slug = slugify(metadata['ten_van_ban'])[:50]\n",
        "        items.append({'metadata':metadata,'path':name_slug})\n",
        "        folder_path = os.path.join('documents', name_slug)\n",
        "        os.makedirs(folder_path, exist_ok=True)\n",
        "        with open(os.path.join(folder_path, 'content.txt'), 'w', encoding='utf-8') as f:\n",
        "            f.write(text)\n",
        "        with open(os.path.join(folder_path, 'content.html'), 'w', encoding='utf-8') as f:\n",
        "            f.write(html)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(url)\n",
        "        continue\n",
        "df = pd.DataFrame(items)\n",
        "# expose metadata\n",
        "df = pd.concat([df, df['metadata'].apply(pd.Series)], axis=1)\n",
        "df['metadata'] = df['metadata'].apply(lambda x: json.dumps(x, ensure_ascii=False))\n",
        "df.to_csv('documents/data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_content_for_tree(text):\n",
        "    re_footer = r'^(Bộ luật này đã được Quốc hội .*|Luật này được Quốc hội.*|Bộ luật này được Quốc hội .*|Luật này đã được Quốc hội .*)'\n",
        "    matches = re.split(re_footer, text, flags=re.MULTILINE)\n",
        "    text = matches[0]\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "luat-bao-hiem-xa-hoi-2014\n",
            "van-ban-hop-nhat-2089-vbhn-bhxh-nam-2020-hop-nhat-\n",
            "thong-tu-59-2015-tt-bldtbxh-quy-dinh-chi-tiet-va-h\n",
            "nghi-dinh-115-2015-nd-cp-huong-dan-luat-bao-hiem-x\n",
            "nghi-dinh-146-2018-nd-cp-huong-dan-luat-bao-hiem-y\n",
            "nghi-dinh-28-2015-nd-cp-huong-dan-luat-viec-lam-ve\n",
            "luat-viec-lam-2013\n",
            "bo-luat-lao-dong-2019\n",
            "thong-tu-56-2017-tt-byt-ve-huong-dan-luat-bao-hiem\n",
            "nghi-dinh-134-2015-nd-cp-huong-dan-luat-bao-hiem-x\n",
            "quyet-dinh-28-2021-qd-ttg-quy-dinh-ve-thuc-hien-ch\n",
            "luat-bao-hiem-y-te-2008\n",
            "luat-bao-hiem-y-te-sua-doi-2014\n",
            "quyet-dinh-166-qd-bhxh-nam-2019-ve-quy-trinh-giai-\n",
            "nghi-dinh-61-2020-nd-cp-ve-sua-doi-nghi-dinh-28-20\n"
          ]
        }
      ],
      "source": [
        "CREATE_CONTENT_TREE=False\n",
        "df = pd.read_csv('documents/data.csv')\n",
        "for row in df.itertuples():\n",
        "    print(row.path)\n",
        "    folder_path = os.path.join('documents', row.path)\n",
        "    text = open(os.path.join(folder_path, 'content.txt'), encoding='utf-8').read()\n",
        "    raw_text = text\n",
        "    text = make_content_for_tree(text)\n",
        "    if CREATE_CONTENT_TREE:\n",
        "        with open(os.path.join(folder_path, 'content_tree.txt'), 'w', encoding='utf-8') as f:\n",
        "            f.write(text)\n",
        "    text = open(os.path.join(folder_path, 'content_tree.txt'), encoding='utf-8').read()\n",
        "    tree = Tree(metadata= json.loads(row.metadata),content=text,raw_text=raw_text)\n",
        "    with open(os.path.join(folder_path, 'debug_tree.txt'), 'w', encoding='utf-8') as f:\n",
        "        f.write(str(tree))\n",
        "    with open(os.path.join(folder_path, 'tree.pkl'), 'wb') as f:\n",
        "        pickle.dump(tree, f)\n",
        "    with open(os.path.join(folder_path, 'tree.json'), 'w', encoding='utf-8') as f:\n",
        "        f.write(json.dumps(tree.export(), indent=4, ensure_ascii=False))\n",
        "    with open(os.path.join(folder_path, 'tree.json.gz'), 'wb') as f:\n",
        "        f.write(gzip.compress(json.dumps(tree.export(), ensure_ascii=False).encode('utf-8')))\n",
        "    # with open('documents/{}.json.gz'.format(row.path), 'wb') as f:\n",
        "        # f.write(gzip.compress(json.dumps(tree.export(), ensure_ascii=False).encode('utf-8')))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "research",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
